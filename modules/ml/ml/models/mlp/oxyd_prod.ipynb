{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T15:39:12.792515508Z",
     "start_time": "2023-07-20T15:39:11.653139917Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib import *\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3772806/2183540496.py:52: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  audio_input = gr.inputs.Audio(label=\"Sélectionnez un fichier audio\", type=\"filepath\")\n",
      "/tmp/ipykernel_3772806/2183540496.py:52: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  audio_input = gr.inputs.Audio(label=\"Sélectionnez un fichier audio\", type=\"filepath\")\n",
      "/tmp/ipykernel_3772806/2183540496.py:53: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  output_prediction = gr.outputs.Textbox(label=\"Prédiction\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\"accapella\", \"accoustic\", \"electro\"]\n",
    "\n",
    "def vector_to_class_label(vector):\n",
    "    max_index = np.argmax(vector)\n",
    "    return classes[max_index]\n",
    "\n",
    "def mp3_to_image(mp3_file, size):\n",
    "    sacrifice_signal, sample_rate = librosa.load(mp3_file)\n",
    "    librosa.display.waveshow(sacrifice_signal, sr=sample_rate)\n",
    "    plt.savefig(\"out.png\")\n",
    "\n",
    "\n",
    "    image = Image.open(\"out.png\").convert(\"L\")\n",
    "\n",
    "    image_resized = image.resize((size, size))\n",
    "\n",
    "    img_array = np.array(image_resized)\n",
    "\n",
    "    img_flattened = img_array.flatten()\n",
    "\n",
    "    os.remove(\"out.png\")\n",
    "\n",
    "    return img_flattened\n",
    "\n",
    "model = load_mlp_model(b\"oxyd_alpha.model\")\n",
    "\n",
    "def audio_chunker(audio_file):\n",
    "    size = 10\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "\n",
    "    duration_ms = len(audio)\n",
    "\n",
    "    chunk_duration_ms = 30 * 1000\n",
    "\n",
    "    chunk = audio[:chunk_duration_ms]\n",
    "\n",
    "    temp_file = \"temp_chunk.mp3\"\n",
    "    chunk.export(temp_file, format=\"mp3\")\n",
    "    song_array = mp3_to_image(temp_file, size)\n",
    "\n",
    "\n",
    "    prediction = predict_mlp_model(model, song_array, True, 3)\n",
    "    prediction = vector_to_class_label(prediction)\n",
    "\n",
    "    os.remove(temp_file)\n",
    "\n",
    "    print(prediction)\n",
    "\n",
    "    return str(prediction)\n",
    "\n",
    "\n",
    "audio_input = gr.inputs.Audio(label=\"Sélectionnez un fichier audio\", type=\"filepath\")\n",
    "output_prediction = gr.outputs.Textbox(label=\"Prédiction\")\n",
    "\n",
    "iface = gr.Interface(fn=audio_chunker, inputs=[audio_input], outputs=output_prediction)\n",
    "iface.launch()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T15:39:12.971166906Z",
     "start_time": "2023-07-20T15:39:12.803724074Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectrogram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
